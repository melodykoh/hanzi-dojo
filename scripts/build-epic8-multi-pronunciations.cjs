#!/usr/bin/env node

/**
 * Build Epic 8 multi-pronunciation dataset (Category 1 + Category 2)
 *
 * Reads canonical dictionary expansion data and synthesizes Pattern A friendly
 * pronunciation payloads for every pending character (139 total).
 *
 * Output: data/multi_pronunciation_epic8_auto.json
 */

const fs = require('fs')
const path = require('path')

const category1Chars = [
  'ä¸º','ä¼ ','ä¾›','ä¾¿','å‡','å‡ ','åˆ‡','åˆ’','åœ°','åœº','å°†','å¹²','åº”','å¼¹','æ‰«','æŠŠ','æ‹…','æ•™','æ›´','æ­£','æ²¡','ç›¸','çœ','ç§','ç³»','ç»“','ç»™','è¡Œ','è§‰','è§’','è°ƒ','è¿˜','éƒ½','é‡','é‡','ä»€'
]

const category2Chars = [
  'ä¸”','ä¸½','ä¹ˆ','ä¹˜','äºŽ','äºš','äº›','äº²','ä»…','ä»Ž','ä»·','ä»»','ä»½','ä¼‘','ä¼°','ä½“','ä¿¡','ä¿©','å€’','å…±','å…¶','å†’','å‡€','å‡‰','åˆ«','åˆ·','åŠ©','åŒ–','åŒ™','åŒº','å ','å¡','åŽ‹','å¥','å¯','å°','å·','å„','åˆ','åŒ','å¦','å§','å‘€','å‘¢','å’–','å’³','å¡«','å¤«','å¥‡','å¦»','å­™','åº•','åº¦','å¼„','æ€','æ„‰','æˆ','æ‰“','æ‹©','æ‹¾','æ®','æŽ’','æ•£','æ—','æ™¯','æœ','æ¡','æŸ¥','æ ¡','æ¤…','æ±—','æ±¤','æ²™','æ´—','æµŽ','çˆ¶','ç‰‡','ç”š','ç–‘','ç ”','ç¡•','ç¥¨','ç¦','ç¨','çº¦','è‚š','èƒ³','è†','è‹¹','è¢«','è§‚','è®º','è¯­','è°','è´£','èµš','è¶Ÿ','è¶£','è·³','é’¢'
]

const allChars = Array.from(new Set([...category1Chars, ...category2Chars]))

const dictionaryPath = path.join(__dirname, '../data/dictionary_expansion_v2.json')
const dictionary = JSON.parse(fs.readFileSync(dictionaryPath, 'utf8'))

const dictionaryBySimp = new Map()
for (const entry of dictionary.entries) {
  if (!dictionaryBySimp.has(entry.simp)) {
    dictionaryBySimp.set(entry.simp, [])
  }
  dictionaryBySimp.get(entry.simp).push(entry)
}

function normalizeTone(tone) {
  return tone && tone.trim() ? tone.trim() : 'Ë‰'
}

function cloneZhuyinTuple(tuple) {
  const [initial = '', final = '', tone = 'Ë‰'] = tuple
  return [initial, final, normalizeTone(tone)]
}

function parsePinyinString(pinyin, expectedLength) {
  if (!pinyin) {
    return Array(expectedLength).fill('')
  }
  const tokens = pinyin
    .split(/[,/;ã€]|\bor\b/i)
    .map(token => token.trim())
    .filter(Boolean)
  if (tokens.length === 0) tokens.push('')
  while (tokens.length < expectedLength) {
    tokens.push(tokens[tokens.length - 1] || tokens[0] || '')
  }
  return tokens.slice(0, expectedLength)
}

function pickDictionaryEntry(char) {
  const matches = dictionaryBySimp.get(char)
  if (!matches || matches.length === 0) {
    throw new Error(`No dictionary entry found for ${char}`)
  }
  const singleCharEntry = matches.find(entry => entry.simp.length === 1)
  return singleCharEntry || matches[0]
}

function buildCharacterPayload(char) {
  const entry = pickDictionaryEntry(char)
  const zhuyinList = (entry.zhuyin || []).map(cloneZhuyinTuple)

  if (zhuyinList.length < 2) {
    console.warn(`âš ï¸  Character ${char} only has ${zhuyinList.length} zhuyin entries; skipping variant build`)
  }

  const pinyinList = parsePinyinString(entry.pinyin || '', zhuyinList.length)

  const defaultPronunciation = {
    pinyin: pinyinList[0] || entry.pinyin || '',
    zhuyin: zhuyinList[0] ? [zhuyinList[0]] : [],
    context_words: [],
    meanings: entry.meanings || []
  }

  const variants = []
  for (let i = 1; i < zhuyinList.length; i++) {
    variants.push({
      pinyin: pinyinList[i] || '',
      zhuyin: [zhuyinList[i]],
      context_words: [],
      meanings: entry.meanings || []
    })
  }

  return {
    simp: entry.simp,
    trad: entry.trad || entry.simp,
    default_pronunciation: defaultPronunciation,
    variants,
    notes: 'Auto-generated from dictionary_expansion_v2.json (no manual context words)',
    source: entry.frequency_rank ? `HSK frequency #${entry.frequency_rank}` : 'dictionary_expansion_v2'
  }
}

const characters = allChars.map(buildCharacterPayload)

const payload = {
  phase: 'Epic 8 - Category 1 + 2 auto-generated pronunciations',
  date: new Date().toISOString().split('T')[0],
  character_count: characters.length,
  description: 'Auto-generated pronunciations for remaining multi-tone characters prior to Drill A guardrails.',
  characters
}

const outputPath = path.join(__dirname, '../data/multi_pronunciation_epic8_auto.json')
fs.writeFileSync(outputPath, JSON.stringify(payload, null, 2))

console.log('âœ… Multi-pronunciation dataset written to', outputPath)
console.log(`ðŸ“Š Characters processed: ${characters.length}`)
